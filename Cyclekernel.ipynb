{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import struct\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.kernel_approximation import *\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "class CycleKernel(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, sigma=-1, num_components=100):\n",
    "        self.sigma, self.num_components = sigma, num_components\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.red = [None] * len(X)\n",
    "        if self.sigma > 0:\n",
    "            self.approx = RBFSampler(gamma=self.sigma, n_components=self.num_components, random_state=10).fit(X[0][0])\n",
    "        for i in range(len(X)):\n",
    "            print(\"fit: \", i/len(X))\n",
    "            mat = [np.zeros((1,self.num_components),dtype=np.float64)] * len(X[i])\n",
    "            for cyc in range(len(X[i])):\n",
    "                if self.sigma == -1:\n",
    "                    mat[cyc] = np.mean(X[i][cyc], axis=0)[np.newaxis,:]\n",
    "                else:\n",
    "                    mat[cyc] = np.mean(self.approx.transform(X[i][cyc]), axis=0)[np.newaxis,:]                    \n",
    "            self.red[i] = np.concatenate(mat, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        mat = np.zeros([len(X), len(self.red)])\n",
    "        if len(self.red) == len(X):\n",
    "            for i in range(len(X)):\n",
    "                print(\"transform: \", i/len(X))\n",
    "                for j in range(i, len(X)):\n",
    "                    mat[i,j] = np.mean(np.matmul(self.red[i], self.red[j].T))\n",
    "                    mat[j,i] = mat[i,j]\n",
    "        else:\n",
    "            red2 = []\n",
    "            for i in range(len(X)):\n",
    "                mat2 = []\n",
    "                for cyc in range(len(X[i])):\n",
    "                        if self.sigma == -1:\n",
    "                            mat2.append(  np.mean(X[i][cyc], axis=0)[np.newaxis,:]  )\n",
    "                        else:\n",
    "                            mat2.append(  np.mean(self.approx.transform(X[i][cyc]), axis=0)[np.newaxis,:]  )\n",
    "            red2.append( np.concatenate(mat2, axis=0) )\n",
    "            for i in range(len(X)):\n",
    "                for j in range(len(self.red)):\n",
    "                    mat[i,j] = np.mean(np.matmul(red2[i], self.red[j].T))\n",
    "        return mat\n",
    "    \n",
    "class Compute_CycleKernel(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_cyckernel(bnd, dims, normalize, scale=1.0):\n",
    "        '''\n",
    "        Compute cycle kernel distance for persistence homology\n",
    "        -- Input\n",
    "        - bnd:  output from function read_bnd_red_unifieddim (format must be compatible)\n",
    "        - dims: persistence homology dimensions, 2 for 2D files, 3 for 3D files\n",
    "        - normalize: if normalize the cyckernel distances\n",
    "        - scale: scale of the normalized distances\n",
    "        -- Output:\n",
    "            In case of 3D input, the output is in form of [[#files X #files]] * 3:\n",
    "            0 dimension, 1 dimension, 2 dimension\n",
    "        '''\n",
    "        assert(dims == len(bnd[0]))\n",
    "        file_number = len(bnd)\n",
    "        cycs_grand_list = [None] * dims\n",
    "\n",
    "        for dim in range(dims):\n",
    "            dim_list = [None] * file_number\n",
    "            for i in range(file_number):\n",
    "                cyc_list = [None] * len(bnd[i][dim])\n",
    "                for j in range(len(cyc_list)):\n",
    "                    cyc_list[j] = np.transpose(bnd[i][dim][j])\n",
    "                dim_list[i] = cyc_list\n",
    "            kernel = CycleKernel(sigma=10.).fit(dim_list)\n",
    "            trfmed = kernel.transform(dim_list)\n",
    "\n",
    "            if normalize:\n",
    "                for i in range(file_number):\n",
    "                    trfmed[i,:] = trfmed[i,:] / np.linalg.norm(trfmed[i,:]) * scale\n",
    "            cycs_grand_list[dim] = trfmed\n",
    "        return cycs_grand_list\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_cyckernel_wThreshold(bnd, dims, pers, threshold, normalize, scale=1.0):\n",
    "        '''\n",
    "        Compute cycle kernel distance for persistence homology, the threshold is applied to the persistence\n",
    "        of the structures\n",
    "        -- Input\n",
    "        @bnd:  output from function read_bnd_red_unifieddim (format must be compatible) [[[pt_num x 3] x struct_num] x dim] x file_num\n",
    "        @dims: persistence homology dimensions, 2 for 2D files, 3 for 3D files\n",
    "        @pers: output from read_pers_txt, [[struct_num x 2] x dim] x file_num\n",
    "        @threshold: threshold for persistence\n",
    "        @normalize: if normalize the cyckernel distances\n",
    "        @scale: scale of the normalized distances\n",
    "        -- Output:\n",
    "            In case of 3D input, the output is in form of [[#files X #files]] * 3:\n",
    "            0 dimension, 1 dimension, 2 dimension\n",
    "        '''\n",
    "        assert(dims == len(bnd[0]))\n",
    "        file_number = len(bnd)\n",
    "        kernel_dist = [None] * dims\n",
    "\n",
    "        for dim in range(dims):\n",
    "            dim_list = [None] * file_number\n",
    "            for i in range(file_number):\n",
    "                persistence = pers[i][dim][:,1] - pers[i][dim][:,0] >= threshold\n",
    "                cyc_list = [None] * np.sum(persistence)\n",
    "                cnt = 0\n",
    "                for j in range(len(persistence)):\n",
    "                    if persistence[j]:\n",
    "                        cyc_list[cnt] = np.transpose(bnd[i][dim][j])\n",
    "                        cnt = cnt + 1\n",
    "                dim_list[i] = cyc_list\n",
    "            kernel = CycleKernel(sigma=10.).fit(dim_list)\n",
    "            trfmed = kernel.transform(dim_list)\n",
    "            \n",
    "            if normalize:\n",
    "                for i in range(file_number):\n",
    "                    trfmed[i,:] = trfmed[i,:] / np.linalg.norm(trfmed[i,:]) * scale\n",
    "            kernel_dist[dim] = trfmed\n",
    "            print(\"dimension \", dim, \" completes...\")\n",
    "            \n",
    "        return kernel_dist\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_cyckernel_wBornDeathLimit(bnd, dims, pers, labels, mode_born, threshold_born,\n",
    "                                          mode_death, threshold_death, normalize, scale=1.0):\n",
    "        '''\n",
    "        Compute cycle kernel distance for persistence homology, the threshold is applied to the birth\n",
    "        and/or death time. labels is imported here as some subjects will not have any structure left\n",
    "        after thresholding, and these structures will be deleted for classification\n",
    "        -- Input\n",
    "        @bnd:  output from function read_bnd_red_unifieddim (format must be compatible) [[[pt_num x 3] x struct_num] x dim] x file_num\n",
    "        @dims: persistence homology dimensions, 2 for 2D files, 3 for 3D files\n",
    "        @pers: output from read_pers_txt, [[struct_num x 2] x dim] x file_num\n",
    "        @labels: [file_num]\n",
    "        @mode_born: operator for birth time, example: \">=\", \"<=\", \"dummy\"(not use)\n",
    "        @threshold_born: -650, not use if mode_born == \"dummy\"\n",
    "        @mode_death: operator for death time, example: \">=\", \"<=\", \"dummy\"(not use)\n",
    "        @threshold_death: -650, not use if mode_death == \"dummy\"\n",
    "        @normalize: if normalize the cyckernel distances\n",
    "        @scale: scale of the normalized distances\n",
    "        -- Output:\n",
    "            In case of 3D input, the output is in form of [[#files X #files]] * 3:\n",
    "            0 dimension, 1 dimension, 2 dimension\n",
    "        '''\n",
    "        assert(dims == len(bnd[0]))\n",
    "        file_number = len(bnd)\n",
    "        assert(len(labels) == file_number)\n",
    "        kernel_dist = [None] * dims\n",
    "        filt_labels = [None] * dims\n",
    "\n",
    "        for dim in range(dims):\n",
    "            dim_list = []\n",
    "            dim_labels = []\n",
    "            for i in range(file_number):\n",
    "                if (mode_born==\">=\"):\n",
    "                    born_filt = pers[i][dim][:,0] >= threshold_born\n",
    "                elif (mode_born==\"<=\"):\n",
    "                    born_filt = pers[i][dim][:,0] <= threshold_born\n",
    "                elif (mode_born==\"dummy\"):\n",
    "                    born_filt = [True] * pers[i][dim].shape[0]\n",
    "                else:\n",
    "                    print(\"Error input for variable: mode_born\")\n",
    "                    \n",
    "                if (mode_death==\">=\"):\n",
    "                    death_filt = pers[i][dim][:,1] >= threshold_death\n",
    "                elif (mode_death==\"<=\"):\n",
    "                    death_filt = pers[i][dim][:,1] <= threshold_death\n",
    "                elif (mode_death==\"dummy\"):\n",
    "                    death_filt = [True] * pers[i][dim].shape[0]\n",
    "                else:\n",
    "                    print(\"Error input for variable: mode_death\")\n",
    "                    \n",
    "                combined_filt = np.logical_and(born_filt, death_filt)\n",
    "                if (np.sum(combined_filt) == 0):\n",
    "                    continue\n",
    "                \n",
    "                cyc_list = [None] * np.sum(combined_filt)\n",
    "                cnt = 0\n",
    "                for j in range(len(combined_filt)):\n",
    "                    if combined_filt[j]:\n",
    "                        cyc_list[cnt] = np.transpose(bnd[i][dim][j])\n",
    "                        cnt = cnt + 1\n",
    "                dim_list.append(cyc_list)\n",
    "                dim_labels.append(labels[i])\n",
    "            kernel = CycleKernel(sigma=10.).fit(dim_list)\n",
    "            trfmed = kernel.transform(dim_list)\n",
    "            \n",
    "            if normalize:\n",
    "                for i in range(len(dim_labels)):\n",
    "                    trfmed[i,:] = trfmed[i,:] / np.linalg.norm(trfmed[i,:]) * scale\n",
    "            kernel_dist[dim] = trfmed\n",
    "            filt_labels[dim] = dim_labels\n",
    "            print(\"dimension \", dim, \" completes...\")\n",
    "            \n",
    "        return kernel_dist, filt_labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_bnd_or_red_by_mask(target, mask):\n",
    "        '''\n",
    "        Remove the parts of topological structures that reside outside of the mask\n",
    "        @target: bnd or red for single file [[3 x pt_num] x struct_num] x dim\n",
    "        @mask: corresponding binary mask\n",
    "        '''\n",
    "        dims = len(target)\n",
    "        assert(dims == 3)\n",
    "        filtered_target = [None] * dims\n",
    "        \n",
    "        cnt = 0\n",
    "        for dim in range(dims):\n",
    "            for i in range(len(target[dim])):\n",
    "                for j in range(target[dim][i].shape[1]):\n",
    "                    x = target[dim][i][2,j]\n",
    "                    y = target[dim][i][1,j]\n",
    "                    z = target[dim][i][0,j]\n",
    "                    if (mask[x][y][z] == 0):\n",
    "                        cnt = cnt + 1\n",
    "        print(\"Number of points out of mask:\", cnt)\n",
    "                \n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_bnd_or_red(target, pers, threshold):\n",
    "        '''\n",
    "        @target: bnd or red for single file [[3 x pt_num] x struct_num] x dim\n",
    "        @pers: persistence for single file [struct_num x 2] x dim\n",
    "        @threshold: threshold for persistence\n",
    "        '''\n",
    "        dims = len(pers)\n",
    "        assert(dims == len(target))\n",
    "        filtered_target = [None] * dims\n",
    "        \n",
    "        for dim in range(dims):\n",
    "            persistence = pers[dim][:,1] - pers[dim][:,0] >= threshold\n",
    "            print('%.3f' %(np.sum(persistence)/(pers[dim].shape[0])*100))\n",
    "            cyc_list = [None] * np.sum(persistence)\n",
    "            cnt = 0\n",
    "            for i in range(len(persistence)):\n",
    "                if persistence[i]:\n",
    "                    cyc_list[cnt] = target[dim][i]\n",
    "                    cnt = cnt + 1\n",
    "            filtered_target[dim] = cyc_list\n",
    "        return filtered_target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
