{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import struct\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from random import randrange\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.kernel_approximation import *\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import f1_score\n",
    "%run Utility_general.ipynb\n",
    "\n",
    "class Utility_MEDICAL(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def dilate_binary_mask(data, iterations):\n",
    "        data = data.astype('int32')\n",
    "        return ndimage.morphology.binary_dilation(data, iterations=iterations).astype(data.dtype)\n",
    "    \n",
    "    @staticmethod\n",
    "    def erode_binary_mask(data, iterations):\n",
    "        data = data.astype('int32')\n",
    "        return ndimage.morphology.binary_erosion(data, iterations=iterations).astype(data.dtype)\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(data, scale):\n",
    "        num = data.shape[0]\n",
    "        for i in range(num):\n",
    "            data[i,:] = data[i,:] / np.linalg.norm(data[i,:]) * scale\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def shrink_box(data):\n",
    "        '''\n",
    "        This function shrinks the whole volume to the mask region\n",
    "        3D data is required\n",
    "        '''\n",
    "        data = data.astype('int32')\n",
    "        shape = data.shape\n",
    "        for i in range(shape[0]-1, -1, -1):\n",
    "            if np.sum(data[i,:,:]) > 0:\n",
    "                right = i\n",
    "                break\n",
    "        for i in range(shape[0]):\n",
    "            if np.sum(data[i,:,:]) > 0:\n",
    "                left = i\n",
    "                break\n",
    "        for i in range(shape[1]-1, -1, -1):\n",
    "            if np.sum(data[:,i,:]) > 0:\n",
    "                back = i\n",
    "                break\n",
    "        for i in range(shape[1]):\n",
    "            if np.sum(data[:,i,:]) > 0:\n",
    "                front = i\n",
    "                break\n",
    "        for i in range(shape[2]-1, -1, -1):\n",
    "            if np.sum(data[:,:,i]) > 0:\n",
    "                bottom = i\n",
    "                break\n",
    "        for i in range(shape[2]):\n",
    "            if np.sum(data[:,:,i]) > 0:\n",
    "                top = i\n",
    "                break\n",
    "        return [left, right, front, back, top, bottom]\n",
    "    \n",
    "    @staticmethod\n",
    "    def divide_layers_around_core(data, layer_num):\n",
    "        '''\n",
    "        @data: input segmentation, should be binary [0, 1]\n",
    "        @plane: plane example [0, 0, 0], [shape[0]-1,0,0], [0,shape[1]-1,0]\n",
    "        @layer_num: segment the segmentation into layer_num layers according to\n",
    "        their distance from the plane\n",
    "        '''\n",
    "        data = data.astype('int32')\n",
    "        shape = data.shape\n",
    "        dist_vec = np.zeros(np.sum(data==1))\n",
    "        cnt = 0\n",
    "        for i in range(shape[0]-1, -1, -1):\n",
    "            if data[i,int(shape[1]/2),int(shape[2]/2)] == 1:\n",
    "                core = [i, int(shape[1]/2),int(shape[2]/2)]\n",
    "                break\n",
    "        for i in range(shape[0]):\n",
    "            for j in range(shape[1]):\n",
    "                for k in range(shape[2]):\n",
    "                    if data[i,j,k] == 1:\n",
    "                        dist_vec[cnt] = (i-core[0])*(i-core[0])+(j-core[1])*(j-core[1])+(k-core[2])*(k-core[2])\n",
    "                        cnt = cnt + 1\n",
    "        assert(np.amin(dist_vec) == 0)\n",
    "                        \n",
    "        max_dist = np.amax(dist_vec)\n",
    "        dist_layout = np.zeros(layer_num+1)\n",
    "        dist_layout[0] = 0\n",
    "        for i in range(layer_num):\n",
    "            dist_layout[i+1] = max_dist/layer_num * (i+1)\n",
    "        dist_layout[layer_num] = dist_layout[layer_num] + 1\n",
    "            \n",
    "        layers = [None] * layer_num\n",
    "        for i in range(layer_num):\n",
    "            layers[i]  = np.zeros(shape, dtype=np.int32)\n",
    "        cnt = 0\n",
    "        for i in range(shape[0]):\n",
    "            for j in range(shape[1]):\n",
    "                for k in range(shape[2]):\n",
    "                    if data[i,j,k] == 1:\n",
    "                        for interval in range(layer_num):\n",
    "                            if  dist_vec[cnt] >= dist_layout[interval] and dist_vec[cnt] < dist_layout[interval+1]:\n",
    "                                layers[interval][i,j,k] = 1\n",
    "                                break\n",
    "                        cnt = cnt + 1\n",
    "        return layers\n",
    "    \n",
    "    @staticmethod\n",
    "    def divide_layers_against_plane(data, plane, layer_num):\n",
    "        '''\n",
    "        @data: input segmentation, should be binary [0, 1]\n",
    "        @plane: plane example [0, 0, 0], [shape[0]-1,0,0], [0,shape[1]-1,0]\n",
    "        @layer_num: segment the segmentation into layer_num layers according to\n",
    "        their distance from the plane\n",
    "        '''\n",
    "        data = data.astype('int32')\n",
    "        shape = data.shape\n",
    "        dist_vec = np.zeros(np.sum(data==1))\n",
    "        cnt = 0\n",
    "        for i in range(shape[0]):\n",
    "            for j in range(shape[1]):\n",
    "                for k in range(shape[2]):\n",
    "                    if data[i,j,k] == 1:\n",
    "                        dist_vec[cnt] = np.sum(np.abs(np.asarray([i,j,k]) - plane))\n",
    "                        cnt = cnt + 1\n",
    "        max_dist = np.amax(dist_vec)\n",
    "        min_dist = np.amin(dist_vec)\n",
    "        dist_layout = np.zeros(layer_num+1)\n",
    "        dist_layout[0] = 0\n",
    "        for i in range(layer_num):\n",
    "            dist_layout[i+1] = (max_dist - min_dist)/layer_num * (i+1) + min_dist\n",
    "        dist_layout[layer_num] = dist_layout[layer_num] + 1\n",
    "            \n",
    "        layers = [None] * layer_num\n",
    "        for i in range(layer_num):\n",
    "            layers[i]  = np.zeros(shape, dtype=np.int32)\n",
    "        cnt = 0\n",
    "        for i in range(shape[0]):\n",
    "            for j in range(shape[1]):\n",
    "                for k in range(shape[2]):\n",
    "                    if data[i,j,k] == 1:\n",
    "                        for interval in range(layer_num):\n",
    "                            if  dist_vec[cnt] >= dist_layout[interval] and dist_vec[cnt] < dist_layout[interval+1]:\n",
    "                                layers[interval][i,j,k] = 1\n",
    "                                break\n",
    "                        cnt = cnt + 1\n",
    "        return layers\n",
    "    \n",
    "    @staticmethod\n",
    "    def draw_on_volume(data, shape, dim, items):\n",
    "        '''\n",
    "        @data: output from function read_bnd_red_unifieddim\n",
    "        @shape: shape of the original volume\n",
    "        @dim: dim to draw, can be 0, 1, or 2\n",
    "        @items: a list of indices indicating which structures to draw\n",
    "        '''\n",
    "        curtain = np.zeros(shape, dtype=np.int32)\n",
    "        assert(dim < len(data))\n",
    "        assert(len(items) > 0)\n",
    "        for item in items:\n",
    "            assert(item < len(data[dim]))\n",
    "            for i in range(data[dim][item].shape[1]):\n",
    "                curtain[data[dim][item][2,i]][data[dim][item][1,i]][data[dim][item][0,i]] = 1\n",
    "        return curtain\n",
    "    \n",
    "    @staticmethod\n",
    "    def draw_on_volume_ori_intensity(data, vol, seg, tum, erode_iter, kernel_size, dim, items, val_range):\n",
    "        '''\n",
    "        @data: output from function read_bnd_red_unifieddim\n",
    "        @vol: volume with original intensity\n",
    "        @seg: binary segmentation\n",
    "        @dim: dim to draw, can be 0, 1, or 2\n",
    "        @items: a list of indices indicating which structures to draw\n",
    "        '''\n",
    "        assert(seg.shape == vol.shape)\n",
    "        assert(dim < len(data))\n",
    "        assert(len(items) > 0)\n",
    "        curtain = np.zeros(vol.shape, dtype=np.float32)\n",
    "        seg = Utility_MEDICAL.erode_binary_mask(seg, erode_iter)\n",
    "        if kernel_size > 0:\n",
    "            kernel = Util_gen.generate_gaussian_kernel(kernel_size, 1, 3)\n",
    "        for item in items:\n",
    "            assert(item < len(data[dim]))\n",
    "            for i in range(data[dim][item].shape[1]):\n",
    "                x = data[dim][item][2,i]\n",
    "                y = data[dim][item][1,i]\n",
    "                z = data[dim][item][0,i]\n",
    "                if seg[x,y,z] == 1 and tum[x,y,z] == 0:\n",
    "                    curtain[x][y][z] = 1\n",
    "        if kernel_size > 0:\n",
    "            curtain = signal.convolve(curtain, kernel, mode='same')\n",
    "            new_curtain = np.ones(vol.shape, dtype=np.float32) * np.amin(vol)\n",
    "            new_curtain[curtain > 1] = vol[curtain > 1]\n",
    "        else:\n",
    "            new_curtain = np.ones(vol.shape, dtype=np.float32) * np.amin(vol)\n",
    "            new_curtain[curtain > 0] = np.random.uniform(low=val_range[0], high=val_range[1], size=vol.shape)[curtain > 0]\n",
    "            #new_curtain[curtain > 0] = vol[curtain > 0]\n",
    "        return new_curtain\n",
    "    \n",
    "    @staticmethod\n",
    "    def align_tumor_segmentations(pathVol, pathSeg, pathOut, ext):\n",
    "        \n",
    "        def create_bounding_box(shape, dim):\n",
    "            dim0 = shape[1] - shape[0] + 1\n",
    "            dim1 = shape[3] - shape[2] + 1\n",
    "            dim2 = shape[5] - shape[4] + 1\n",
    "            diff0 = dim - dim0\n",
    "            diff1 = dim - dim1\n",
    "            diff2 = dim - dim2\n",
    "            dim0_left  = int(np.floor(diff0 / 2.0))\n",
    "            dim1_left  = int(np.floor(diff1 / 2.0))\n",
    "            dim2_left  = int(np.floor(diff2 / 2.0))\n",
    "            return [dim0_left, dim0_left+dim0-1, dim1_left, dim1_left+dim1-1,\n",
    "                    dim2_left, dim2_left+dim2-1]\n",
    "        '''\n",
    "        @pathVol: path to volume folder example: \"E:/Data2/BreastMass_refine/volumes\"\n",
    "        @pathSeg: path to tumor segmentation folder example: \"E:/Data2/BreastMass_refine/tumors_mask\"\n",
    "        @pathOut: path to output tumor mask folder example: \"E:/Data2/BreastMass_refine/tumors\"\n",
    "        @ext: extension of the target files example: \"nii\"\n",
    "        '''\n",
    "        idx_arr = []\n",
    "        filesVol = []\n",
    "        filesSeg = []\n",
    "        filesOut  = []\n",
    "        os.chdir(pathVol)\n",
    "        for file in glob.glob(\"*.\"+ext):\n",
    "            idx_arr.append(file.split('_')[1])\n",
    "            filesVol.append(os.path.join(pathVol, file))\n",
    "            filesOut.append(os.path.join(pathOut, file.split('_')[0]+'_'+file.split('_')[1]+'_tumor.nii'))\n",
    "        os.chdir(pathSeg)\n",
    "        cnt = 0\n",
    "        for file in glob.glob(\"*.\"+ext):\n",
    "            idx_ = file.split('_')[1]\n",
    "            assert(idx_arr[cnt] == idx_)\n",
    "            filesSeg.append(os.path.join(pathSeg, file))\n",
    "            cnt = cnt + 1\n",
    "        \n",
    "        dim0_arr = np.zeros(len(filesSeg), dtype=np.int32)\n",
    "        dim1_arr = np.zeros(len(filesSeg), dtype=np.int32)\n",
    "        dim2_arr = np.zeros(len(filesSeg), dtype=np.int32)\n",
    "        for i in range(len(filesSeg)):\n",
    "            seg = FileIO_MEDICAL.load_nii(filesSeg[i])\n",
    "            srk_shape = Utility_MEDICAL.shrink_box(seg)\n",
    "            dim0_arr[i] = srk_shape[1] - srk_shape[0] + 1\n",
    "            dim1_arr[i] = srk_shape[3] - srk_shape[2] + 1\n",
    "            dim2_arr[i] = srk_shape[5] - srk_shape[4] + 1\n",
    "        print(np.amax(dim0_arr), np.amax(dim1_arr), np.amax(dim2_arr))\n",
    "        \n",
    "        unified_dim = 256\n",
    "        Path(pathOut).mkdir(parents=True, exist_ok=True)\n",
    "        for i in range(len(filesSeg)):\n",
    "            seg = FileIO_MEDICAL.load_nii(filesSeg[i])\n",
    "            srk_shape = Utility_MEDICAL.shrink_box(seg)\n",
    "            rmd_shape = create_bounding_box(srk_shape, unified_dim)\n",
    "            vol = FileIO_MEDICAL.load_nii(filesVol[i])\n",
    "            min_val = np.amin(vol)-1\n",
    "            vol[seg==0] = min_val\n",
    "            tum = np.ones((unified_dim,unified_dim,unified_dim),dtype=vol.dtype) * min_val\n",
    "            tum[rmd_shape[0]:rmd_shape[1]+1, rmd_shape[2]:rmd_shape[3]+1, rmd_shape[4]:rmd_shape[5]+1]=vol[srk_shape[0]:srk_shape[1]+1, srk_shape[2]:srk_shape[3]+1, srk_shape[4]:srk_shape[5]+1]\n",
    "            FileIO_MEDICAL.save_nii(tum, filesOut[i])\n",
    "    \n",
    "    def generate_tda_volumes(pathTDA, pathOut, threshold, target_dim, dil_iter, labels,\n",
    "                             fromVol, kernel_size, sigma, patchMode, patch_shape=(0,0,0)):\n",
    "        '''\n",
    "        This function draws extracted topological features on empty volumes.\n",
    "        The output volumes have the same spatial size.\n",
    "        @pathTDA: path to TDA results folder example: \"E:/Data2/BreastMass_refine/sup\"\n",
    "        @pathOut: path to output tumor mask folder example: \"E:/Data2/BreastMass_refine/tumors\"\n",
    "        @threshold: threshold to filter tda structures\n",
    "        @target_dim: which dimension to draw, 0 1 or 2\n",
    "        @dil_iter: iterations to dilate mask, int\n",
    "        @labels: int\n",
    "        @fromVol: if the intensity of the tda structures are actual volume intensity, bool\n",
    "        @kernel_size: kernel size of the 3D gaussian kernel\n",
    "        @sigma: sigma of the 3D gaussian kernel\n",
    "        @patchMode: if to sample patch, bool\n",
    "        @patch_shape: if patchMode is true, define the shape of the sample\n",
    "        '''\n",
    "\n",
    "        def probe_dimensions(files):\n",
    "            num = len(files)\n",
    "            dim0_arr = np.zeros(num, dtype=np.int32)\n",
    "            dim1_arr = np.zeros(num, dtype=np.int32)\n",
    "            dim2_arr = np.zeros(num, dtype=np.int32)\n",
    "            for i in range(num):\n",
    "                vol = FileIO_MEDICAL.read_dat(files[i])\n",
    "                dim0_arr[i] = vol.shape[0]\n",
    "                dim1_arr[i] = vol.shape[1]\n",
    "                dim2_arr[i] = vol.shape[2]\n",
    "            print(np.amax(dim0_arr), np.amax(dim1_arr), np.amax(dim2_arr))\n",
    "            return dim0_arr, dim1_arr, dim2_arr\n",
    "\n",
    "        def create_bounding_box(shape, dim):\n",
    "                dim0 = shape[0]\n",
    "                dim1 = shape[1]\n",
    "                dim2 = shape[2]\n",
    "                diff0 = dim - dim0\n",
    "                diff1 = dim - dim1\n",
    "                diff2 = dim - dim2\n",
    "                dim0_left  = int(np.floor(diff0 / 2.0))\n",
    "                dim1_left  = int(np.floor(diff1 / 2.0))\n",
    "                dim2_left  = int(np.floor(diff2 / 2.0))\n",
    "                return [dim0_left, dim0_left+dim0-1, dim1_left, dim1_left+dim1-1,\n",
    "                        dim2_left, dim2_left+dim2-1]\n",
    "\n",
    "        def sample_patch(data, sample_shape):\n",
    "            shape = data.shape\n",
    "            dims = len(shape)\n",
    "            assert(dims == 3)\n",
    "            assert(len(sample_shape) == dims)\n",
    "            for dim in range(dims):\n",
    "                if not sample_shape[dim] <= shape[dim]:\n",
    "                    return []\n",
    "            num = int(np.floor(np.prod(shape) / np.prod(sample_shape)))\n",
    "            dim0 = shape[0] - sample_shape[0]\n",
    "            dim1 = shape[1] - sample_shape[1]\n",
    "            dim2 = shape[2] - sample_shape[2]\n",
    "            patches = [None] * num\n",
    "            for i in range(num):\n",
    "                s0 = randrange(dim0+1)\n",
    "                s1 = randrange(dim1+1)\n",
    "                s2 = randrange(dim2+1)\n",
    "                patch = data[s0:s0+sample_shape[0],s1:s1+sample_shape[1],s2:s2+sample_shape[2]]\n",
    "                patches[i] = patch\n",
    "            return patches\n",
    "\n",
    "        filesVol  = []\n",
    "        filesBnd  = []\n",
    "        filesPers = []\n",
    "        filesOut  = []\n",
    "        label_cnt = 0\n",
    "        os.chdir(pathTDA)\n",
    "        for file in glob.glob(\"*.dat\"):\n",
    "            filesVol.append(os.path.join(pathTDA, file))\n",
    "            filesOut.append(os.path.join(pathOut, file.split('_')[0]+'_'+file.split('_')[1]+'_'+str(labels[label_cnt])+'_TDA.nii'))   \n",
    "            label_cnt = label_cnt + 1\n",
    "        for file in glob.glob(\"*.bnd\"):\n",
    "            filesBnd.append(os.path.join(pathTDA, file))\n",
    "        for file in glob.glob(\"*.pers.txt\"):\n",
    "            filesPers.append(os.path.join(pathTDA, file))\n",
    "        num = len(filesVol)\n",
    "        assert(num == len(filesBnd))\n",
    "        assert(num == len(filesPers))\n",
    "        assert(num == len(labels))\n",
    "        dim0_arr, dim1_arr, dim2_arr = probe_dimensions(filesVol)\n",
    "        if kernel_size > 0:\n",
    "            kernel = Util_gen.generate_gaussian_kernel(kernel_size, sigma, 3)\n",
    "\n",
    "        patch_cnt = 0\n",
    "        unified_dim = 256\n",
    "        Path(pathOut).mkdir(parents=True, exist_ok=True)\n",
    "        for i in range(num):\n",
    "            bnd = FileIO_MEDICAL.read_bnd_red_unifieddim(filesBnd[i])\n",
    "            pers = FileIO_MEDICAL.read_pers_txt(filesPers[i])\n",
    "            bnd_filt = Compute_CycleKernel.filter_bnd_or_red(bnd, pers, threshold)\n",
    "#             bnd_drw = Utility_MEDICAL.draw_on_volume(bnd_filt, (dim0_arr[i], dim1_arr[i], dim2_arr[i]),\n",
    "#                                                      target_dim, np.arange(0,len(bnd_filt[target_dim])))\n",
    "\n",
    "            bnd_drw0 = Utility_MEDICAL.draw_on_volume(bnd_filt, (dim0_arr[i], dim1_arr[i], dim2_arr[i]),\n",
    "                             1, np.arange(0,len(bnd_filt[1])))\n",
    "            bnd_drw1 = Utility_MEDICAL.draw_on_volume(bnd_filt, (dim0_arr[i], dim1_arr[i], dim2_arr[i]),\n",
    "                             2, np.arange(0,len(bnd_filt[2])))\n",
    "            bnd_drw = bnd_drw0 | bnd_drw1\n",
    "\n",
    "            if (dil_iter > 0):\n",
    "                bnd_drw = Utility_MEDICAL.dilate_binary_mask(bnd_drw, dil_iter)\n",
    "            if (fromVol):\n",
    "                vol = FileIO_MEDICAL.read_dat(filesVol[i])\n",
    "                vol = -vol\n",
    "                #vol = vol + np.abs(np.amin(vol)) + 1\n",
    "                vol[bnd_drw==0] = np.amin(vol)\n",
    "                bnd_drw = vol\n",
    "            if (kernel_size > 0):\n",
    "                bnd_drw = signal.convolve(bnd_drw, kernel, mode='same')\n",
    "            if (patchMode):\n",
    "                patches = sample_patch(bnd_drw, patch_shape)\n",
    "                for j in range(len(patches)):\n",
    "                    patch_path = os.path.join(pathOut, 'ISPY_'+str(patch_cnt)+'_'+str(labels[i])+'_TDA.nii')\n",
    "                    patch_cnt = patch_cnt + 1\n",
    "                    FileIO_MEDICAL.save_nii(patches[j], patch_path)\n",
    "            else:\n",
    "                rmd_shape = create_bounding_box(bnd_drw.shape, unified_dim)\n",
    "                tum = np.ones((unified_dim,unified_dim,unified_dim),dtype=np.float32) * np.amin(bnd_drw)\n",
    "                tum[rmd_shape[0]:rmd_shape[1]+1, rmd_shape[2]:rmd_shape[3]+1, rmd_shape[4]:rmd_shape[5]+1]=bnd_drw\n",
    "                FileIO_MEDICAL.save_nii(tum, filesOut[i])\n",
    "    \n",
    "    @staticmethod\n",
    "    def mass_srk_volume_segmentation(pathVol, pathSeg, pathTum, pathOutVol, pathOutSeg, pathOutTum, ext):\n",
    "        '''\n",
    "        @pathVol: path to volumes\n",
    "        @pathSeg: path to breast segmentations\n",
    "        @pathOutVol: path to output shrinked volumes\n",
    "        @pathOutSeg: path to output shrinked segmentations\n",
    "        @ext: extension of the target files example: \"nii\"\n",
    "        '''\n",
    "        idx_arr = []\n",
    "        filesVol = []\n",
    "        filesSeg = []\n",
    "        filesTum = []\n",
    "        outVol = []\n",
    "        outSeg = []\n",
    "        outTum = []\n",
    "        os.chdir(pathVol)\n",
    "        for file in glob.glob(\"*.\"+ext):\n",
    "            idx_arr.append(file.split('_')[1])\n",
    "            filesVol.append(os.path.join(pathVol, file))\n",
    "            outVol.append(os.path.join(pathOutVol, file.split('_')[0]+'_'+file.split('_')[1]+'_vol2_srk.nii'))\n",
    "            outSeg.append(os.path.join(pathOutSeg, file.split('_')[0]+'_'+file.split('_')[1]+'_seg_srk.nii'))\n",
    "            outTum.append(os.path.join(pathOutTum, file.split('_')[0]+'_'+file.split('_')[1]+'_tum_srk.nii'))\n",
    "        os.chdir(pathSeg)\n",
    "        cnt = 0\n",
    "        for file in glob.glob(\"*.\"+ext):\n",
    "            idx_ = file.split('_')[1]\n",
    "            assert(idx_arr[cnt] == idx_)\n",
    "            filesSeg.append(os.path.join(pathSeg, file))\n",
    "            cnt = cnt + 1\n",
    "        os.chdir(pathTum)\n",
    "        cnt = 0\n",
    "        for file in glob.glob(\"*.\"+ext):\n",
    "            idx_ = file.split('_')[1]\n",
    "            assert(idx_arr[cnt] == idx_)\n",
    "            filesTum.append(os.path.join(pathTum, file))\n",
    "            cnt = cnt + 1\n",
    "        for i in range(len(filesVol)):\n",
    "            vol = FileIO_MEDICAL.load_nii(filesVol[i])\n",
    "            seg = FileIO_MEDICAL.load_nii(filesSeg[i])\n",
    "            tum = FileIO_MEDICAL.load_nii(filesTum[i])\n",
    "            seg = Utility_MEDICAL.erode_binary_mask(seg, 2)\n",
    "            dil_outer = Utility_MEDICAL.dilate_binary_mask(seg, 5)\n",
    "            dil_inner = Utility_MEDICAL.dilate_binary_mask(seg, 3)\n",
    "            srk_shape = Utility_MEDICAL.shrink_box(dil_outer)\n",
    "            seg_srk = dil_inner[srk_shape[0]:srk_shape[1]+1, srk_shape[2]:srk_shape[3]+1, srk_shape[4]:srk_shape[5]+1]\n",
    "            vol_srk = vol[srk_shape[0]:srk_shape[1]+1, srk_shape[2]:srk_shape[3]+1, srk_shape[4]:srk_shape[5]+1]\n",
    "            tum_srk = tum[srk_shape[0]:srk_shape[1]+1, srk_shape[2]:srk_shape[3]+1, srk_shape[4]:srk_shape[5]+1]\n",
    "            vol_srk[seg_srk==0] = np.amin(vol)-1\n",
    "            #vol_srk = vol_srk + np.abs(np.amin(vol_srk)) + 1\n",
    "            #vol_srk = vol_srk * 10\n",
    "            FileIO_MEDICAL.save_nii(vol_srk, outVol[i])\n",
    "            #FileIO_MEDICAL.save_nii(seg_srk, outSeg[i])\n",
    "            FileIO_MEDICAL.save_nii(tum_srk, outTum[i])\n",
    "            \n",
    "    @staticmethod\n",
    "    def mass_write_dat(pathIn, pathOut, ext, mode):\n",
    "        os.chdir(pathIn)\n",
    "        for file in glob.glob(\"*.\"+ext):\n",
    "            vol = FileIO_MEDICAL.load_nii(file)\n",
    "            out_path = os.path.join(pathOut, file.split('_')[0]+'_'+file.split('_')[1]+'_vol2_'+mode+'.dat')\n",
    "            if mode == \"sup\":\n",
    "                vol = -vol\n",
    "            FileIO_MEDICAL.write_dat(vol, out_path)\n",
    "            \n",
    "    @staticmethod\n",
    "    def binary_balanced_evaluation(labels, preds):\n",
    "        '''\n",
    "        @labels: ground truth labels\n",
    "        @preds: predicted labels\n",
    "        binary labels with 0 or 1 with balaned formula:\n",
    "        0.5*(correctly_predicted_0/total_num_0 + correctly_predicted_1/total_num1)\n",
    "        '''\n",
    "        labels = np.array(labels)\n",
    "        preds = np.array(preds)\n",
    "        num_0 = np.sum(labels==0)\n",
    "        num_1 = np.sum(labels==1)\n",
    "        correctly_predicted_0 = 0\n",
    "        correctly_predicted_1 = 1\n",
    "        length = len(labels)\n",
    "        for i in range(length):\n",
    "            if labels[i] == preds[i]:\n",
    "                if labels[i] == 0:\n",
    "                    correctly_predicted_0 = correctly_predicted_0 + 1\n",
    "                else:\n",
    "                    correctly_predicted_1 = correctly_predicted_1 + 1\n",
    "        return 0.5 * (correctly_predicted_0/num_0 + correctly_predicted_1/num_1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_accuracy(labels, preds):\n",
    "        '''\n",
    "        @labels: ground truth labels\n",
    "        @preds: predicted labels with the same size as labels\n",
    "        '''\n",
    "        labels = np.array(labels)\n",
    "        preds = np.array(preds)\n",
    "        assert(len(labels) == len(preds))\n",
    "        return np.sum(labels == preds) / float(len(labels))\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_F1(labels, preds):\n",
    "        '''\n",
    "        Compute F1 score which accounts for both precision and sensitivity\n",
    "        @labels: ground truth labels\n",
    "        @preds: predicted labels with the same size as labels\n",
    "        '''\n",
    "        labels = np.array(labels)\n",
    "        preds = np.array(preds)\n",
    "        assert(len(labels) == len(preds))\n",
    "        return f1_score(labels, preds)\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_specificity_sensitivity(labels, preds):\n",
    "        '''\n",
    "        @labels: ground truth labels\n",
    "        @preds: predicted labels with the same size as labels\n",
    "        '''\n",
    "        labels = np.array(labels)\n",
    "        preds = np.array(preds)\n",
    "        assert(len(labels) == len(preds))\n",
    "        cm = metrics.confusion_matrix(labels, preds)\n",
    "        total = sum(sum(cm))\n",
    "        sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "        return specificity, sensitivity\n",
    "    \n",
    "    @staticmethod\n",
    "    def binary_auc_score(labels, preds):\n",
    "        '''\n",
    "        @labels: ground truth labels\n",
    "        @preds: predicted labels\n",
    "        '''\n",
    "        labels = np.array(labels)\n",
    "        preds = np.array(preds)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(labels, preds, pos_label=1)\n",
    "        return metrics.auc(fpr, tpr)\n",
    "    \n",
    "    @staticmethod\n",
    "    def SVC_baseline(feat_train, label_train, feat_test, label_test):\n",
    "        '''\n",
    "        Sample classification, run a grid search for best hyper parameters\n",
    "        '''\n",
    "        c_grid = np.arange(1, 10, 1)\n",
    "        best_acc = np.ones(4, dtype=np.float64) * -1\n",
    "        best_auc = np.ones(4, dtype=np.float64) * -1\n",
    "        for i in range(len(c_grid)):\n",
    "            clf = svm.LinearSVC(penalty='l2', C=c_grid[i])\n",
    "            clf.fit(feat_train, label_train)\n",
    "            res = clf.predict(feat_test)\n",
    "            acc = Utility_MEDICAL.binary_balanced_evaluation(label_test, res)\n",
    "            auc = Utility_MEDICAL.binary_auc_score(label_test, res)\n",
    "            if acc > best_acc[0]:\n",
    "                best_acc[0] = acc\n",
    "            if auc > best_auc[0]:\n",
    "                best_auc[0] = auc\n",
    "            #print(acc)\n",
    "\n",
    "        #print(\"========================================\")\n",
    "        for i in range(len(c_grid)):\n",
    "            clf = svm.SVC(C=c_grid[i])\n",
    "            clf.fit(feat_train, label_train)\n",
    "            res = clf.predict(feat_test)\n",
    "            acc = Utility_MEDICAL.binary_balanced_evaluation(label_test, res)\n",
    "            auc = Utility_MEDICAL.binary_auc_score(label_test, res)\n",
    "            if acc > best_acc[1]:\n",
    "                best_acc[1] = acc\n",
    "            if auc > best_auc[1]:\n",
    "                best_auc[1] = auc\n",
    "            #print(acc)\n",
    "\n",
    "        #print(\"========================================\")\n",
    "        for i in range(len(c_grid)):\n",
    "            clf = svm.SVC(C=c_grid[i], kernel='poly')\n",
    "            clf.fit(feat_train, label_train)\n",
    "            res = clf.predict(feat_test)\n",
    "            acc = Utility_MEDICAL.binary_balanced_evaluation(label_test, res)\n",
    "            auc = Utility_MEDICAL.binary_auc_score(label_test, res)\n",
    "            if acc > best_acc[2]:\n",
    "                best_acc[2] = acc\n",
    "            if auc > best_auc[2]:\n",
    "                best_auc[2] = auc\n",
    "            #print(acc)\n",
    "\n",
    "        #print(\"========================================\")\n",
    "        for i in range(len(c_grid)):\n",
    "            clf = svm.SVC(C=c_grid[i], kernel='sigmoid')\n",
    "            clf.fit(feat_train, label_train)\n",
    "            res = clf.predict(feat_test)\n",
    "            acc = Utility_MEDICAL.binary_balanced_evaluation(label_test, res)\n",
    "            auc = Utility_MEDICAL.binary_auc_score(label_test, res)\n",
    "            if acc > best_acc[3]:\n",
    "                best_acc[3] = acc\n",
    "            if auc > best_auc[3]:\n",
    "                best_auc[3] = auc\n",
    "        return best_acc, best_auc\n",
    "    \n",
    "    @staticmethod\n",
    "    def probe_persistence(pers, labels, bord, mode, threshold):\n",
    "        '''\n",
    "        This function is to be used in combination with Cyclekernel.compute_cyckernel_wBornDeathLimit\n",
    "        It does not compute anything, but to probe persistence and find reasonable birth, death threshold\n",
    "        @pers: output from read_pers_txt, [[struct_num x 2] x dim] x file_num\n",
    "        @labels: [file_num]\n",
    "        @bord: birth or death, 0 for birth, 1 for death\n",
    "        @mode: \">=\" or \"<=\"\n",
    "        @treshold: double\n",
    "        '''\n",
    "        file_num = len(pers)\n",
    "        assert(file_num == len(labels))\n",
    "        dims = len(pers[0])\n",
    "        cnt0 = np.zeros(dims, dtype=np.float32)\n",
    "        cnt1 = np.zeros(dims, dtype=np.float32)\n",
    "        num0 = np.sum(labels==0)\n",
    "        num1 = np.sum(labels==1)\n",
    "        \n",
    "        for i in range(file_num):\n",
    "            if mode == \">=\":\n",
    "                for dim in range(dims):\n",
    "                    filt = pers[i][dim][:,bord] >= threshold\n",
    "                    if labels[i] == 0:\n",
    "                        cnt0[dim] = cnt0[dim] + np.sum(filt) / pers[i][dim].shape[0]\n",
    "                    else:\n",
    "                        cnt1[dim] = cnt1[dim] + np.sum(filt) / pers[i][dim].shape[0]\n",
    "            elif mode == \"<=\":\n",
    "                for dim in range(dims):\n",
    "                    filt = pers[i][dim][:,bord] <= threshold\n",
    "                    if labels[i] == 0:\n",
    "                        cnt0[dim] = cnt0[dim] + np.sum(filt) / pers[i][dim].shape[0]\n",
    "                    else:\n",
    "                        cnt1[dim] = cnt1[dim] + np.sum(filt) / pers[i][dim].shape[0]\n",
    "            else:\n",
    "                print(\"Error input mode\")\n",
    "        print(\"Dim 0\", \" 0/1: \", cnt0[0]/num0, \" \", cnt1[0]/num1, \" \", (cnt0[0]/num0)/(cnt1[0]/num1))\n",
    "        print(\"Dim 1\", \" 0/1: \", cnt0[1]/num0, \" \", cnt1[1]/num1, \" \", (cnt0[1]/num0)/(cnt1[1]/num1))\n",
    "        print(\"Dim 2\", \" 0/1: \", cnt0[2]/num0, \" \", cnt1[2]/num1, \" \", (cnt0[2]/num0)/(cnt1[2]/num1))\n",
    "        \n",
    "    @staticmethod\n",
    "    def SVM_classifier(feat, dim, labels, train_percentage, split_num, normalize, pairwise_dist):\n",
    "        '''\n",
    "        @feat: list of n x m matrix, the first matrix is accessed with: feat[0]\n",
    "        @dim: the dimension of features to use\n",
    "        @labels: list of integers\n",
    "        @train_percentage: percentage of samples used for training\n",
    "        @split_num: number of random splits of training and test\n",
    "        @normalize: if to normalize the features\n",
    "        @pairwise_dist: if to delete distances to the test subjects\n",
    "        '''\n",
    "        assert(len(feat) > dim)\n",
    "        file_num = len(labels)\n",
    "        train_num = int(np.floor(file_num * train_percentage))\n",
    "        \n",
    "        best_accuracy = np.zeros(4, dtype=np.float64)\n",
    "        best_auc = np.zeros(4, dtype=np.float64)\n",
    "        for split_ in range(split_num):\n",
    "            train_index = np.array(random.sample(range(0, file_num), train_num))\n",
    "            test_index = []\n",
    "            for i in range(file_num):\n",
    "                if np.sum(train_index == i) == 0:\n",
    "                    test_index.append(i)\n",
    "\n",
    "            train_labels = labels[train_index]\n",
    "            test_labels = labels[test_index]\n",
    "            if pairwise_dist == True:\n",
    "                feat_ = feat[dim][:, train_index]\n",
    "#                 feat0 = feat[0][:, train_index]\n",
    "#                 feat1 = feat[1][:, train_index]\n",
    "#                 feat2 = feat[2][:, train_index]\n",
    "            else:\n",
    "                feat_ = feat[dim]\n",
    "#                 feat0 = feat[0]\n",
    "#                 feat1 = feat[1]\n",
    "#                 feat2 = feat[2]\n",
    "#             feat_ = np.concatenate((feat0,feat1, feat2), axis=1)\n",
    "#             feat_ = feat0\n",
    "            if normalize:\n",
    "                feat_ = Utility_MEDICAL.normalize(feat_, 1.0)\n",
    "\n",
    "            feat_train = feat_[train_index,:]\n",
    "            feat_test = feat_[test_index,:]\n",
    "            cur_acc, cur_auc = Utility_MEDICAL.SVC_baseline(feat_train, train_labels, feat_test, test_labels)\n",
    "            best_accuracy = best_accuracy + cur_acc\n",
    "            best_auc = best_auc + cur_auc\n",
    "            \n",
    "        best_accuracy = best_accuracy / split_num\n",
    "        best_auc = best_auc / split_num\n",
    "        print(best_accuracy)\n",
    "        print(best_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
